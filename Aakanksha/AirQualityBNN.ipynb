{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESSENTIALLY A COPY PASTE OF EXAMPLE BNN\n",
    "\n",
    "# Load libriaries and functions.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tfk = tf.keras\n",
    "tf.keras.backend.set_floatx(\"float64\")\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Define helper functions.\n",
    "scaler = StandardScaler()\n",
    "detector = IsolationForest(n_estimators=1000, behaviour=\"deprecated\", contamination=\"auto\", random_state=0)\n",
    "neg_log_likelihood = lambda x, rv_x: -rv_x.log_prob(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As sensors tend to drift due to aging, it is better to discard the data past month six."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and keep only first six months due to drift.\n",
    "data = pd.read_excel(\"data.xlsx\")\n",
    "try:\n",
    "    data = data[data[\"Date\"] <= \"2004-09-10\"]\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1360.00</td>\n",
       "      <td>150</td>\n",
       "      <td>11.881723</td>\n",
       "      <td>1045.50</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.25</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.00</td>\n",
       "      <td>1267.50</td>\n",
       "      <td>13.60</td>\n",
       "      <td>48.875001</td>\n",
       "      <td>0.757754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1292.25</td>\n",
       "      <td>112</td>\n",
       "      <td>9.397165</td>\n",
       "      <td>954.75</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1173.75</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1558.75</td>\n",
       "      <td>972.25</td>\n",
       "      <td>13.30</td>\n",
       "      <td>47.700000</td>\n",
       "      <td>0.725487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1402.00</td>\n",
       "      <td>88</td>\n",
       "      <td>8.997817</td>\n",
       "      <td>939.25</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.00</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1554.50</td>\n",
       "      <td>1074.00</td>\n",
       "      <td>11.90</td>\n",
       "      <td>53.975000</td>\n",
       "      <td>0.750239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1375.50</td>\n",
       "      <td>80</td>\n",
       "      <td>9.228796</td>\n",
       "      <td>948.25</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.00</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1583.75</td>\n",
       "      <td>1203.25</td>\n",
       "      <td>11.00</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.786713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-03-10</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1272.25</td>\n",
       "      <td>51</td>\n",
       "      <td>6.518224</td>\n",
       "      <td>835.50</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.00</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1490.00</td>\n",
       "      <td>1110.00</td>\n",
       "      <td>11.15</td>\n",
       "      <td>59.575001</td>\n",
       "      <td>0.788794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      Time  CO(GT)  PT08.S1(CO)  NMHC(GT)   C6H6(GT)  \\\n",
       "0 2004-03-10  18:00:00     2.6      1360.00       150  11.881723   \n",
       "1 2004-03-10  19:00:00     2.0      1292.25       112   9.397165   \n",
       "2 2004-03-10  20:00:00     2.2      1402.00        88   8.997817   \n",
       "3 2004-03-10  21:00:00     2.2      1375.50        80   9.228796   \n",
       "4 2004-03-10  22:00:00     1.6      1272.25        51   6.518224   \n",
       "\n",
       "   PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)  \\\n",
       "0        1045.50    166.0       1056.25    113.0       1692.00      1267.50   \n",
       "1         954.75    103.0       1173.75     92.0       1558.75       972.25   \n",
       "2         939.25    131.0       1140.00    114.0       1554.50      1074.00   \n",
       "3         948.25    172.0       1092.00    122.0       1583.75      1203.25   \n",
       "4         835.50    131.0       1205.00    116.0       1490.00      1110.00   \n",
       "\n",
       "       T         RH        AH  \n",
       "0  13.60  48.875001  0.757754  \n",
       "1  13.30  47.700000  0.725487  \n",
       "2  11.90  53.975000  0.750239  \n",
       "3  11.00  60.000000  0.786713  \n",
       "4  11.15  59.575001  0.788794  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is quite messy and has to be preprocessed first. We will focus on the inputs and outputs which were measured for most of the time (one sensor died quite early). Data is scaled after removing rows with missing values. Afterwards, outliers are detected and removed using an Isolation Forest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns and remove rows with missing values.\n",
    "columns = [\"PT08.S1(CO)\", \"PT08.S3(NOx)\", \"PT08.S4(NO2)\", \"PT08.S5(O3)\", \"T\", \"AH\", \"CO(GT)\", \"C6H6(GT)\", \"NOx(GT)\", \"NO2(GT)\"]\n",
    "data = data[columns].dropna(axis=0)\n",
    "\n",
    "# Scale data to zero mean and unit variance.\n",
    "X_t = scaler.fit_transform(data)\n",
    "\n",
    "# Remove outliers.\n",
    "is_inlier = detector.fit_predict(X_t)\n",
    "X_t = X_t[(is_inlier > 0),:]\n",
    "\n",
    "# Restore frame.\n",
    "dataset = pd.DataFrame(X_t, columns=columns)\n",
    "\n",
    "# Select labels for inputs and outputs.\n",
    "inputs = [\"PT08.S1(CO)\", \"PT08.S3(NOx)\", \"PT08.S4(NO2)\", \"PT08.S5(O3)\", \"T\", \"AH\"]\n",
    "outputs = [\"CO(GT)\", \"C6H6(GT)\", \"NOx(GT)\", \"NO2(GT)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some hyperparameters.\n",
    "n_epochs = 5\n",
    "n_samples = dataset.shape[0]\n",
    "n_batches = 10\n",
    "batch_size = np.floor(n_samples/n_batches)\n",
    "buffer_size = n_samples\n",
    "\n",
    "# Define training and test data sizes.\n",
    "n_train = int(0.7*dataset.shape[0])\n",
    "\n",
    "# Define dataset instance.\n",
    "data = tf.data.Dataset.from_tensor_slices((dataset[inputs].values, dataset[outputs].values))\n",
    "data = data.shuffle(n_samples, reshuffle_each_iteration=True)\n",
    "\n",
    "# Define train and test data instances.\n",
    "data_train = data.take(n_train).batch(batch_size).repeat(n_epochs)\n",
    "data_test = data.skip(n_train).batch(1).repeat(n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To account for aleotoric uncertainty, which arises from the noise in the output, dense layers are combined with probabilistic layers. More specifically, the mean and covariance matrix of the output is modelled as a function of the input and parameter weights. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Aakanksha 1/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# Define prior for regularization.\n",
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(len(outputs), dtype=tf.float64), scale=1.0), reinterpreted_batch_ndims=1)\n",
    "\n",
    "# Define model instance.\n",
    "model = tfk.Sequential([\n",
    "tfk.layers.InputLayer(input_shape=(len(inputs),), name=\"input\"),\n",
    "tfk.layers.Dense(10, activation=\"relu\", name=\"dense_1\"),\n",
    "tfk.layers.Dense(tfp.layers.MultivariateNormalTriL.params_size(\n",
    "len(outputs)), activation=None, name=\"distribution_weights\"),\n",
    "tfp.layers.MultivariateNormalTriL(len(outputs), activity_regularizer=tfp.layers.KLDivergenceRegularizer(prior, weight=1/n_batches), name=\"output\")\n",
    "], name=\"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb444948590>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model.\n",
    "model.compile(optimizer=\"adam\", loss=neg_log_likelihood)\n",
    "\n",
    "# Run training session.\n",
    "model.fit(data_train, epochs=n_epochs, validation_data=data_test, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                70        \n",
      "_________________________________________________________________\n",
      "distribution_weights (Dense) (None, 14)                154       \n",
      "_________________________________________________________________\n",
      "output (MultivariateNormalTr ((None, 4), (None, 4))    0         \n",
      "=================================================================\n",
      "Total params: 224\n",
      "Trainable params: 224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Describe model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To account for aleotoric and epistemic uncertainty (uncertainty in parameter weights), the dense layers have to be exchanged with Flipout layers (DenseFlipout). \n",
    "`tfp.layers.DenseFlipout(10, activation=\"relu\", name=\"dense_1\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is a probabilistic model, a Monte Carlo experiment is performed to provide a prediction. In particular, every prediction of a sample x results in a different output y, which is why the expectation over many individual predictions has to be calculated. Additionally, the variance can be determined this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'IteratorGetNext_9:0' shape=(?, 6) dtype=float64>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict.\n",
    "samples = 500\n",
    "iterations = 10\n",
    "test_iterator = tf.compat.v1.data.make_one_shot_iterator(data_test)\n",
    "X_true, Y_true, Y_pred = np.empty(shape=(samples, len(inputs))), np.empty(shape=(samples, len(outputs))), np.empty(shape=(samples, len(outputs), iterations))\n",
    "\n",
    "print(X_true.shape)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__array__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d3766947db03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mX_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mY_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __array__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "for i in range(samples):\n",
    "    features, labels = test_iterator.get_next()\n",
    "    X_true[i,:] = features\n",
    "    Y_true[i,:] = labels.numpy()\n",
    "    for k in range(iterations):\n",
    "        Y_pred[i,:,k] = model.predict(features)\n",
    "        \n",
    "# Calculate mean and standard deviation.\n",
    "Y_pred_m = np.mean(Y_pred, axis=-1)\n",
    "Y_pred_s = np.std(Y_pred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“slime-rl”",
   "language": "python",
   "name": "slime-rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
